{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f3e382-c8d2-440e-b055-0f5517bfa081",
   "metadata": {},
   "source": [
    "## Exploring Similarity Between Text Embedding Tutorial\n",
    "\n",
    "We can use individual_nlp_explanation to explore how a pre-trained embedding model’s similarity landscape. \n",
    "\n",
    "We provide individual_nlp_explanation with our two texts we want to compare as well as our specified model of choice. The explainer function then returns a list of pairs of terms from each text which are seen be similar and dissimilar by the model\n",
    "\n",
    "Let’s take a simplistic example and generate our similarity increasers and similarity decreasers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3c179a-dc6f-48e7-b828-2c1fa2b10421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decima2 import individual_nlp_explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805a9670-cabf-4c1c-96c2-2001d6bc192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"the cat sat on the mat and it purred\"\n",
    "text2 = \"the dog lay upon the mat and it barked\"\n",
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb00e76f-1209-40d4-a1f7-1a888863a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_increasers, similarity_decreasers = individual_nlp_explanation(text1, text2, model_name, output='text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22f4a27-94b4-4448-a54e-87356488adcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs that increase similarity: ('sat on the mat and it', 'the mat', np.float32(0.16405481))\n",
      "Pairs that increase similarity: ('on the mat and it', 'the dog', np.float32(0.16475308))\n",
      "Pairs that increase similarity: ('the cat sat on the', 'dog lay upon the mat and it', np.float32(0.1664756))\n",
      "Pairs that increase similarity: ('the cat', 'dog lay upon the mat and it', np.float32(0.16682768))\n",
      "Pairs that increase similarity: ('mat and it', 'lay upon', np.float32(0.1682499))\n",
      "Pairs that increase similarity: ('on the mat and it', 'lay upon', np.float32(0.16850364))\n",
      "Pairs that increase similarity: ('sat on', 'dog lay upon the mat and it', np.float32(0.1688664))\n",
      "Pairs that increase similarity: ('cat sat on the mat and it', 'lay upon', np.float32(0.1700396))\n",
      "Pairs that increase similarity: ('sat on the mat and it', 'the dog', np.float32(0.17831814))\n",
      "Pairs that increase similarity: ('sat on the mat and it', 'lay upon', np.float32(0.18724602))\n",
      "\n",
      "Pairs that decrease similarity: ('on the mat and it purred', 'upon the mat and it barked', np.float32(-0.029459774))\n",
      "Pairs that decrease similarity: ('sat on the mat and it', 'lay upon the mat and it', np.float32(-0.028996527))\n",
      "Pairs that decrease similarity: ('and it purred', 'and it barked', np.float32(-0.027228117))\n",
      "Pairs that decrease similarity: ('mat and it purred', 'and it', np.float32(-0.025600016))\n",
      "Pairs that decrease similarity: ('the mat and it purred', 'and it', np.float32(-0.024742484))\n",
      "Pairs that decrease similarity: ('the mat and it purred', 'upon the mat and it', np.float32(-0.024086595))\n",
      "Pairs that decrease similarity: ('on the mat and it', 'lay upon the mat and it', np.float32(-0.022538126))\n",
      "Pairs that decrease similarity: ('on the mat and it purred', 'lay upon the mat and it barked', np.float32(-0.022419631))\n",
      "Pairs that decrease similarity: ('mat and it purred', 'upon the mat and it', np.float32(-0.022259414))\n",
      "Pairs that decrease similarity: ('mat and it', 'the mat and it', np.float32(-0.022044778))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(similarity_increasers)):\n",
    "    print(\"Pairs that increase similarity:\", similarity_increasers[i])\n",
    "print(\"\")\n",
    "for i in range(len(similarity_decreasers)):\n",
    "    print(\"Pairs that decrease similarity:\", similarity_decreasers[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ffa6a-6253-45f4-b95f-f3eb7c269d1b",
   "metadata": {},
   "source": [
    "From these similarity decreasers and increasers we can seee that the terms \"and it purred\" and \"and it barked\" are seen by the embedding model as dissimilar while the terms \"sat on the mat and it\" and \"lay upon\" are seen as most similar. \n",
    "\n",
    "This is interesting, the embedding model has clearly learned that barked and purred are different. Let's try and explore why the model thinks the other two terms are similar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af523e4e-585d-43c6-92e6-e62b2a98b22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"sat on the mat and it\"\n",
    "text2 = \"lay upon\"\n",
    "model_name = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97e4d1d1-351b-42ed-b93e-82a3608b212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_increasers, similarity_decreasers = individual_nlp_explanation(text1, text2, model_name, output='text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "589d751a-3fa0-491d-b585-595f0706effc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs that increase similarity: ('and it', 'upon', np.float32(0.019421458))\n",
      "Pairs that increase similarity: ('and it', 'lay', np.float32(0.020947754))\n",
      "Pairs that increase similarity: ('the mat and', 'lay', np.float32(0.12305528))\n",
      "Pairs that increase similarity: ('the mat and', 'upon', np.float32(0.12549114))\n",
      "\n",
      "Pairs that decrease similarity: ('sat on the mat', 'upon', np.float32(-0.106793344))\n",
      "Pairs that decrease similarity: ('sat on the', 'upon', np.float32(-0.10494733))\n",
      "Pairs that decrease similarity: ('sat on the', 'lay', np.float32(-0.1005885))\n",
      "Pairs that decrease similarity: ('sat on the mat', 'lay', np.float32(-0.0981608))\n",
      "Pairs that decrease similarity: ('sat on', 'upon', np.float32(-0.08655596))\n",
      "Pairs that decrease similarity: ('sat on', 'lay', np.float32(-0.07990849))\n",
      "Pairs that decrease similarity: ('mat and it', 'upon', np.float32(-0.072120726))\n",
      "Pairs that decrease similarity: ('mat and it', 'lay', np.float32(-0.069006324))\n",
      "Pairs that decrease similarity: ('the mat and it', 'upon', np.float32(-0.06892699))\n",
      "Pairs that decrease similarity: ('the mat and it', 'lay', np.float32(-0.067008555))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(similarity_increasers)):\n",
    "    print(\"Pairs that increase similarity:\", similarity_increasers[i])\n",
    "print(\"\")\n",
    "for i in range(len(similarity_decreasers)):\n",
    "    print(\"Pairs that decrease similarity:\", similarity_decreasers[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d46fc-edb6-40f1-84ae-a8f468750975",
   "metadata": {},
   "source": [
    "By decomposing this term we can see that the embedding model has learned that 'the mat and','upon' or 'the mat and','lay' are similar but 'sat on the mat', 'upon' are dissimilar. Interestingly we can infer that the model has learned that we may want to 'lay upon a mat' but we would not 'sit upon the mat'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba19f39-2d30-47ac-ad05-59f272509c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
