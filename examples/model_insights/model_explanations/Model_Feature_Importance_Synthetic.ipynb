{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3dba6b1-a0ff-4a04-8f6a-9ff9c241fce8",
   "metadata": {},
   "source": [
    "## Decima2 feature importances are more accurate than SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472bcfa-a1ae-45c7-8b7e-9112f49276de",
   "metadata": {},
   "source": [
    "This notebook generates a synthetic dataset with causal structure, trains a Random Forest Regressor model on this data and then determines both the Decima2 and SHAP feature importance explanations for this model. We show that Decima2 explanations are not only faster, but more faithfully recover the true causal structure in the data than SHAP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af2513-ed09-436d-b901-7b0101f6a64c",
   "metadata": {},
   "source": [
    "First we import all relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6582dd1a-30bc-49a1-b373-7bfe27e8d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "from decima2 import model_feature_importance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from decima2.utils.utils import feature_names\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0561a4a6-a386-4230-8f22-d9ebc0f4a5fb",
   "metadata": {},
   "source": [
    "## Function Design and Creation of Synthetic Data \n",
    "We now design our dataset where we randomly generate 3 independent variables $x_{1}$, $x_{2}$ and $x_{3}$ all from the same distributions. We then create $x_{4}$, $x_{5}$ as causally directly dependent on $x_{2}$ and $x_{1}$. \n",
    "\n",
    "We then design our function $f = (2*x_{1}) + 3 * x_{2} + x_{3}$ and use a Random Forest Regressor to learn this function. \n",
    "\n",
    "What are the Actual Importances\n",
    "\n",
    "From this design we argue, from an importance perspective, the importance of $x_{1}$ is equal to the importance of $x_{5}$ as these features are completey interchangeable. From a business perspective, given a situation where $x_{1}$ represents weekly sales and $x_{5}$ represents  weekly transactions, both of these features could be used by the model to the same effect when predicting $f$. \n",
    "\n",
    "<it> Note that some people may disagree with this assumption and argue that $x_{1}$ should be assigned all the importance where $x_{5}$ is given none as $x_{1}$ the causal ancestor of $x_{5}$, and $x_{5}$ isn't even used by the function to make decisions! This type of functionality will be offered in our next release of model explanations so you can tailor your use case to your needs. </it>\n",
    "\n",
    "This gives us a ground truth feature importance ordering of \n",
    "<ul> \n",
    "   <li> $x_{2}$ </li> \n",
    "   <li> $x_{4}$ </li> \n",
    "    <li> $x_{1}$ </li>\n",
    "    <li> $x_{5}$ </li>\n",
    "   <li> $x_{3}$ </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85b7eb1d-4616-4d85-9892-b73f35f03db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_data(n): \n",
    "    x_1 = np.random.normal(0, 2, size=(n))\n",
    "    x_2 = np.random.normal(0, 2, size=(n))\n",
    "    x_3 = np.random.normal(0, 2, size=(n))\n",
    "    x_4 = x_2\n",
    "    x_5 = x_1\n",
    "    y = (2 * x_1) + (3 * x_2) + x_3\n",
    "    X = pd.DataFrame()\n",
    "    X['X_1']= x_1\n",
    "    X['X_2'] = x_2\n",
    "    X['X_3']= x_3\n",
    "    X['X_4']= x_4\n",
    "    X['X_5'] = x_5\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c999b68f-f058-4ddb-9ad4-1f50ca4f2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_data(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b45cba72-f8f8-4465-aa2e-499f3c37f96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9961376369273085"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "model = RandomForestRegressor(max_depth=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86695610-ab71-49ef-82d1-9adb1fc62c74",
   "metadata": {},
   "source": [
    "## Decima2 Feature Importance Explanations\n",
    "\n",
    "We now generate our Decima2 explanations for our test data and trained Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7e8d08b-72fa-4803-9b9d-9993c76756e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.655003070831299\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_2</td>\n",
       "      <td>1.84186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_4</td>\n",
       "      <td>1.84186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_3</td>\n",
       "      <td>1.05662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_1</td>\n",
       "      <td>0.83642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_5</td>\n",
       "      <td>0.83642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Importance\n",
       "1     X_2     1.84186\n",
       "3     X_4     1.84186\n",
       "2     X_3     1.05662\n",
       "0     X_1     0.83642\n",
       "4     X_5     0.83642"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "explanation_app = model_feature_importance(X_test,y_test,model,output='text')\n",
    "et = time.time()\n",
    "print(et-st)\n",
    "explanation_app\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc6ff1-30fe-4f1d-a0f6-5bc1089bc74e",
   "metadata": {},
   "source": [
    "## SHAP explanations\n",
    "\n",
    "We now generate our SHAP explanations for our test data and trained Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fd58342-1cda-40fd-bd65-c7ee9e421377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 1994/2000 [01:00<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.592472076416016\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "explainer = shap.Explainer(model, X_test)\n",
    "shap_values = explainer(X_test,check_additivity=False)\n",
    "et = time.time()\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d20e2785-d947-4715-a892-b784487b00b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X_1</td>\n",
       "      <td>0.38393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_5</td>\n",
       "      <td>0.38209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X_3</td>\n",
       "      <td>0.14086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X_4</td>\n",
       "      <td>0.11148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X_2</td>\n",
       "      <td>0.09290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature  Importance\n",
       "0     X_1     0.38393\n",
       "4     X_5     0.38209\n",
       "2     X_3     0.14086\n",
       "3     X_4     0.11148\n",
       "1     X_2     0.09290"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributions = shap_values.values.mean(axis=0)\n",
    "attributions = attributions.reshape(X_test.shape[1])\n",
    "feature_names(X_test,attributions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2617b2-8754-4873-92e6-a1ef35a1534f",
   "metadata": {},
   "source": [
    "We can see that our SHAP explanations take 30x more time than our Decima2 explanations! We can also see that Decima2 recovers our true feature importances whereas the SHAP explanations dont identify either $x_{2}$ or $x_{4}$ as the most important feature. AKA SHAP explanations are completely wrong even if we ignore our causal assumption from earlier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2b3c3-869c-41ad-83aa-2568068ac573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
